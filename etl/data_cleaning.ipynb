{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from pyspark.sql.functions import col,when,count,mean,regexp_replace,split, to_date, initcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read import save_as_single_csv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_dictionary):\n",
    "    for data_file_name in data_dictionary:\n",
    "        try:\n",
    "            logging.info(f\"Cleaning {data_file_name} dataframe\")\n",
    "            \n",
    "            # Identify missing values from the dataframe\n",
    "            logging.info(\"Checking for missing values\")\n",
    "            check_for_missing_values(data_dictionary[data_file_name])\n",
    "\n",
    "            # Handle missing values\n",
    "            logging.info(\"Handling missing values\")\n",
    "            data_dictionary[data_file_name] = handle_missing_values(data_dictionary[data_file_name])\n",
    "\n",
    "            # Remove duplicates\n",
    "            logging.info(\"Removing duplicates\")\n",
    "            data_dictionary[data_file_name] = remove_duplicated(data_dictionary[data_file_name])\n",
    "\n",
    "            # Correct inaccurate data\n",
    "            logging.info(\"Correcting inaccurate data\")\n",
    "            data_dictionary[data_file_name] = accurate_data(data_file_name, data_dictionary[data_file_name])\n",
    "            logging.info(\"Successfully cleaned data for customers dataFrame\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error cleaning {data_file_name} dataFrame: {e}\", exc_info=True)\n",
    "            \n",
    "\n",
    "        logging.info(\".....................................................................................................................\")            \n",
    "\n",
    "    # Save cleaned dataframes into cleaned data folder as a csv file\n",
    "    try:\n",
    "        logging.info(\"Saving cleaned dataframes\")\n",
    "        save_as_csv(data_dictionary)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving cleaned dataframes: {e}\", exc_info=True)\n",
    "    \n",
    "    return data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in dataFrame\n",
    "def check_for_missing_values(dataframe):\n",
    "    try:\n",
    "        #checking missing values in dataframe\n",
    "        dataframe.select([count(when(col(c).isNull(), c)) \\\n",
    "            .alias(c) for c in dataframe.columns])\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error checking for missing values\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "def handle_missing_values(dataframe):\n",
    "    try:\n",
    "        #Handling missing values in dataframe\n",
    "        if \"Email\" in dataframe.columns and \"Phone\" in dataframe.columns:\n",
    "            # Fill unknown at the place of null value\n",
    "            dataframe = dataframe.na.fill({'Email': 'NA', 'Phone': \"NA\"})\n",
    "\n",
    "        if \"Category\" in dataframe.columns:\n",
    "            # Fill unknown at the place of null value in category column\n",
    "            dataframe = dataframe.na.fill({\"Category\": \"unknown\"})\n",
    "\n",
    "        if \"Amount\" in dataframe.columns:\n",
    "            # Find the avg of Amount column\n",
    "            avg_amount = dataframe.select(mean(col(\"Amount\"))).first()[0]\n",
    "            # Fill avg of amount column at null place\n",
    "            dataframe = dataframe.na.fill({\"Amount\": avg_amount})\n",
    "\n",
    "        if \"Interaction_Type\" in dataframe.columns:\n",
    "            # Fill NA in the interaction type\n",
    "            dataframe = dataframe.na.fill({'Interaction_Type': \"NA\"})\n",
    "\n",
    "        if \"Sales_Achieved\" in dataframe.columns:\n",
    "            # Find the avg of Sales_Achieved column\n",
    "            avg_sales_achieved = dataframe.select(mean(col(\"Sales_Achieved\"))).first()[0]\n",
    "            # Fill Null values in Sales_Achieved column with avg of the column\n",
    "            dataframe = dataframe.na.fill({\"Sales_Achieved\": avg_sales_achieved})\n",
    "\n",
    "        if \"Country_Code\" in dataframe.columns:\n",
    "            dataframe = dataframe.na.fill({'Country_Code': 'NA'})\n",
    "\n",
    "        # Check if there are any missing values\n",
    "        check_for_missing_values(dataframe)\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error handling missing values\", exc_info=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate data\n",
    "def remove_duplicated(dataframe):\n",
    "    try:\n",
    "        logging.info(f\"{dataframe.count()} total records.\")\n",
    "        dataframe = dataframe.dropDuplicates()\n",
    "        logging.info(f\"{dataframe.count()} records left after dropping duplicates.\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error removing duplicates\", exc_info=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and formatting dataFrame\n",
    "def accurate_data(data_file_name, dataframe):\n",
    "    try:\n",
    "        if data_file_name == \"customers\":\n",
    "            dataframe = correct_customer_data(dataframe)\n",
    "        else:\n",
    "            dataframe = correct_inaccurate_data(dataframe)\n",
    "            \n",
    "        return dataframe    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error correcting inaccurate data for {data_file_name}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting customer data\n",
    "def correct_customer_data(dataframe):\n",
    "    try:\n",
    "        dataframe = dataframe.withColumn(\"Phone\", split(col(\"Phone\"), \"x\")[0])\n",
    "        # Remove the '+1' prefix if it exists\n",
    "        dataframe = dataframe.withColumn(\n",
    "            \"Phone\",\n",
    "            when(col(\"Phone\").startswith(\"+1\"),\n",
    "                col(\"Phone\").substr(2, 100)\n",
    "            ).otherwise(col(\"Phone\"))\n",
    "        )\n",
    "        dataframe = dataframe.withColumn(\n",
    "            \"Phone\",\n",
    "            when(col(\"Phone\").startswith(\"001\"),\n",
    "                col(\"Phone\").substr(3, 100)\n",
    "            ).otherwise(col(\"Phone\"))\n",
    "        )\n",
    "        # Remove all non-numeric values\n",
    "        dataframe = dataframe.withColumn(\"Phone\", \n",
    "            when(col(\"Phone\") != \"NA\", regexp_replace(col(\"Phone\"), r\"[^0-9]\", \"\")) \\\n",
    "            .otherwise(col(\"Phone\"))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error formatting customer data\", exc_info=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and format data from dataFrame based on column name\n",
    "def correct_inaccurate_data(dataframe):\n",
    "    try:\n",
    "        if \"Amount\" in dataframe.columns:\n",
    "            dataframe = dataframe.filter(col('Amount') > 0)\n",
    "            # Standardize date formats\n",
    "        if \"Date\" in dataframe.columns:\n",
    "            dataframe = dataframe.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "        if \"Interaction_Date\" in dataframe.columns:\n",
    "            dataframe = dataframe.withColumn(\"Interaction_Date\", to_date(col(\"Interaction_Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "        if \"Name\" in dataframe.columns:\n",
    "            # Capitalize names\n",
    "            dataframe = dataframe.withColumn(\"Name\", initcap(col(\"Name\")))\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error correcting inaccurate data\", exc_info=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join customer df with country code df and get the joined dataFrame\n",
    "def join_customer_country_code(customer_df, country_codes_df):\n",
    "    try:\n",
    "        # Join cleaned customer df and country_codes_df\n",
    "        join_customer_df = customer_df.join(country_codes_df, 'Country', \"left\")\n",
    "        customer_df_columns = customer_df.columns\n",
    "        customer_df = join_customer_df.select(*customer_df_columns, 'Country_Code')\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error joining customer and country code data\", exc_info=True)\n",
    "    \n",
    "    return customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataFrame into csv file\n",
    "def save_as_csv(data_dictionary):\n",
    "    output_dir = \"/spark-data/data/cleaned\"\n",
    "    for data_file_name in data_dictionary:\n",
    "        try:\n",
    "            save_as_single_csv(data_dictionary[data_file_name], f\"{output_dir}/{data_file_name}.csv\")\n",
    "            logging.info(f\"{data_file_name} saved successfully\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving {data_file_name} to CSV\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
